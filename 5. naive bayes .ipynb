{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize\n",
    "\n",
    "columns = defaultdict(list)\n",
    "tweets = []\n",
    "sentiment = []\n",
    "tweetCollection = []\n",
    "def readCSVTweet(fileName):\n",
    "    with open(fileName) as f:\n",
    "        reader = csv.DictReader(f) # read rows into a dictionary format\n",
    "        for row in reader: # read a row as {column1: value1, column2: value2,...}\n",
    "            for (k,v) in row.items(): # go over each column name and value \n",
    "                columns[k].append(v) # append the value into the appropriate list\n",
    "                                    # based on column name k\n",
    "    tweets = columns[\"clean_tweet\"]\n",
    "    for tweet in tweets:\n",
    "        words = word_tokenize(tweet)\n",
    "        tweetCollection.append(words)\n",
    "    return tweetCollection\n",
    "\n",
    "def readCSVSenti(fileName):\n",
    "    with open(fileName) as f:\n",
    "        reader = csv.DictReader(f) # read rows into a dictionary format\n",
    "        for row in reader: # read a row as {column1: value1, column2: value2,...}\n",
    "            for (k,v) in row.items(): # go over each column name and value \n",
    "                columns[k].append(v) # append the value into the appropriate list\n",
    "                                    # based on column name k\n",
    "    sentiment= columns[\"clean_sentiment\"]\n",
    "    return sentiment\n",
    "\n",
    "def merge(list1, list2): \n",
    "      \n",
    "    merged_list = [(list1[i], list2[i]) for i in range(0, len(list1))] \n",
    "    return merged_list \n",
    "\n",
    "trainingData= merge(readCSVTweet(\"Demo.csv\"),readCSVSenti(\"Demo.csv\"))\n",
    "#testData= merge(readCSVTweet(\"optusSVM.csv\"),readCSVSenti(\"optusSVM.csv\"))    \n",
    "#trainingData=dict(zip(readCSVTweet(\"Dummy.csv\"), readCSVSenti(\"Dummy.csv\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def buildVocabulary(trainingData):\n",
    "    collectionOfAllWords = []\n",
    "    \n",
    "    for (words, sentiment) in trainingData:\n",
    "        collectionOfAllWords.extend(words)\n",
    "\n",
    "    wordlist = nltk.FreqDist(collectionOfAllWords)\n",
    "    featureOfWords = wordlist.keys()\n",
    "    \n",
    "    return featureOfWords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extractionOfFeature(tweet):\n",
    "    wordsInTweet = set(tweet)\n",
    "    features = {}\n",
    "    for word in wordFeature:\n",
    "        features['contains(%s)' % word] = (word in wordsInTweet)\n",
    "        \n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordFeature = buildVocabulary(trainingData)\n",
    "\n",
    "trainingFeature = nltk.classify.apply_features(extractionOfFeature, trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NBClassifier = nltk.NaiveBayesClassifier.train(trainingFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NBLabels = [NBClassifier.classify(extractionOfFeature(tweet[0])) for tweet in trainingData]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NBLabels.count('positive')> NBLabels.count('negative'):\n",
    "    print (\"Positive Sentiment Result: \" + str(100*NBLabels.count('positive')/len(NBLabels))+ \"%\")\n",
    "else:\n",
    "    print (\"Negative Sentiment Result: \" + str(100*NBLabels.count('negative')/len(NBLabels)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#nltk.classify.util.accuracy(NBClassifier, testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBLabels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
